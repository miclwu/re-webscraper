from bs4 import BeautifulSoup
import requests
#import json
import re
import hashlib
import time
from enum import Enum
from requests.exceptions import HTTPError
from utilities import csv_to_dict, dict_to_csv

# TODO:
# - revamp input/output system
#   - output changed funds to a separate csv file as well, accept input for manual fund status change
#   - OR sort main csv by last changed so manual editing is easier
# - report fund amount if possible
#   - 2 new fields: fund amount and path/id to html element containing fund amount (or maybe find it thru api?)
# - deployment
#   - AWS server w/ simple SQL database?
#   - privileged users need to be able to request/modify data
# - add way to add/remove to PHRASES, FIELDNAMES(?)
# - checksum specific element(s) instead of checking <body> text
# - 2-bit predictor?
# - proxies
# - NOTE: scraper does not detect page changes if only text generated by js was changed.

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Accept": "text/html,application/xhtml+xml",
    "Accept-Language": "en-US,en;q=0.9"
}

PHRASES = ["not.{0,100}accept.{0,100}application(s?)",
           "application(s?).{0,150}are(?!.{0,50}\bnot\b).{0,50}closed",
           "no open call(s?).{0,50}application(s?)",
           "are(?!.{0,50}\bnot\b).{0,50}closed",
           "not.{0,50}offering.{0,50}fund"]

#"(we|there)(?!.{0,50}\bnot\b).{0,50}waiting list"

FIELDNAMES = ["name", "url", "status", "checksum"]

class Status(Enum):
    OPEN = "Open"
    CLOSED = "Closed"
    CHECK = "Check Required"

DELIM = ";;"

DATAFILE = "database_TEST.csv"

def get_soup(url, retries= 5, backoff= 2):
    for attempt in range(retries):
        try:
            response = requests.get(url, headers=HEADERS)
            if 'text/html' not in response.headers['content-type']:
                raise TypeError
            response.raise_for_status()
            soup = BeautifulSoup(response.text, "html.parser")

            return soup
        
        except TypeError as e:
            wait_time = backoff ** attempt
            print(f'TypeError: {e}. Retrying in {wait_time} seconds...')
            time.sleep(wait_time)

        except HTTPError as e:
            if e.response.status_code == 412:
                print(f'Error 412. Skipping "{url}"...')
                return None
            wait_time = backoff ** attempt
            print(f'HTTP error: {e}. Retrying in {wait_time} seconds...')
            time.sleep(wait_time)
            
        except Exception as e:
            print(f'Failed to reach URL: {url}. Error: {e}. Skipping...')
            return None
    return None

def main():
    database = csv_to_dict(DATAFILE)

    for item in database:
        assert(item["name"])
        assert(item["url"])
        assert(item["status"] == Status.OPEN.value or item["status"] == Status.CLOSED.value or item["status"] == Status.CHECK.value)

        isChecksumNew = False
        foundPhrase = False

        old_checksum = item["checksum"]
        checksum = ""

        for url in item["url"].split(DELIM):
        
            soup = get_soup(url)

            if not soup:
                continue
            
            checksum += hashlib.sha256("".join(soup.body.text.split()).encode('utf-8')).hexdigest()

            for p in PHRASES:
                tags = soup.body.find_all(string=re.compile(p, re.IGNORECASE))
                if len(tags) > 0:
                    foundPhrase = True
                    print(f'{item["name"]}, PHRASE TAGS: {tags}')
        
        if not old_checksum:
            item["checksum"] = checksum
            print(f'{item["name"]}, {item["status"].upper()} FUND: Adding new checksum.')
            continue

        if checksum != old_checksum:
            isChecksumNew = True
        
        match (item["status"], isChecksumNew, foundPhrase):
            case (Status.OPEN.value, False, False) | (Status.OPEN.value, False, True)| (Status.CLOSED.value, False, False) | (Status.CHECK.value, False, False) | (Status.CHECK.value, False, True):
                print(f'{item["name"]}, {item["status"].upper()} FUND: Checksums match.')
            case (Status.OPEN.value, True, False) | (Status.OPEN.value, True, True):
                item["status"] = Status.CHECK
                item["checksum"] = checksum
                print(f'{item["name"]}, OPEN FUND: Page change detected. Updating checksum. Check required.')
            case (Status.CLOSED.value, True, False) | (Status.CLOSED.value, True, True):
                item["status"] = Status.CHECK
                item["checksum"] = checksum
                print(f'{item["name"]}, CLOSED FUND: Page change detected. Updating checksum. Check required.')
            case (Status.CHECK.value, True, False) | (Status.CHECK.value, True, True):
                item["checksum"] = checksum
                print(f'{item["name"]}, CHECK FUND: Updating checksum.')

    dict_to_csv(database, DATAFILE, FIELDNAMES)

if __name__ == "__main__":
    main()
